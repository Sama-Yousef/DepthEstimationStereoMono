{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "491aa060",
      "metadata": {
        "id": "491aa060"
      },
      "source": [
        "Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yzbg4VPfosB7",
      "metadata": {
        "id": "yzbg4VPfosB7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xme4xHyLvjBk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xme4xHyLvjBk",
        "outputId": "9358bee5-795c-4dab-8ed2-e99e6ec9e433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cCk_aFTZoths",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCk_aFTZoths",
        "outputId": "96741a3f-e110-4a8c-cf32-e464be870037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uint8 2 255\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "path = \"/content/drive/MyDrive/data/images/gt_depth/469.png\"\n",
        "gt = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "print(gt.dtype, gt.min(), gt.max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_4CpIod5RvfV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4CpIod5RvfV",
        "outputId": "99007d6e-a257-47d8-c7f1-993fc61d915a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ تم إنشاء الفيديو: depth_video.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "# فولدر الصور الناتجة\n",
        "image_folder = \"/content/output_depth\"\n",
        "video_name = \"depth_video.mp4\"\n",
        "\n",
        "# اقرأ كل الصور و رتبهم بالاسم\n",
        "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
        "images.sort()  # مهم عشان الترتيب\n",
        "\n",
        "# اقرأ أول صورة لتحديد أبعاد الفيديو\n",
        "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
        "height, width, layers = frame.shape\n",
        "\n",
        "# إعداد الفيديو (30 fps)\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # كودك للفيديو\n",
        "video = cv2.VideoWriter(video_name, fourcc, 10, (width, height))\n",
        "\n",
        "# أضف كل الصور للفيديو\n",
        "for img in images:\n",
        "    frame = cv2.imread(os.path.join(image_folder, img))\n",
        "    video.write(frame)\n",
        "\n",
        "video.release()\n",
        "print(f\"✅ تم إنشاء الفيديو: {video_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7feed0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b7feed0",
        "outputId": "46b8d397-1774-4374-9618-a2518485c3d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/output_depth/ (stored 0%)\n",
            "  adding: content/output_depth/507_depth.png (deflated 19%)\n",
            "  adding: content/output_depth/472_depth.png (deflated 16%)\n",
            "  adding: content/output_depth/510_depth.png (deflated 19%)\n",
            "  adding: content/output_depth/514_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/505_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/511_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/495_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/486_depth.png (deflated 26%)\n",
            "  adding: content/output_depth/483_depth.png (deflated 18%)\n",
            "  adding: content/output_depth/513_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/494_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/471_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/501_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/476_depth.png (deflated 14%)\n",
            "  adding: content/output_depth/508_depth.png (deflated 18%)\n",
            "  adding: content/output_depth/509_depth.png (deflated 19%)\n",
            "  adding: content/output_depth/512_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/469_depth.png (deflated 14%)\n",
            "  adding: content/output_depth/484_depth.png (deflated 19%)\n",
            "  adding: content/output_depth/490_depth.png (deflated 23%)\n",
            "  adding: content/output_depth/466_depth.png (deflated 16%)\n",
            "  adding: content/output_depth/470_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/481_depth.png (deflated 16%)\n",
            "  adding: content/output_depth/491_depth.png (deflated 18%)\n",
            "  adding: content/output_depth/482_depth.png (deflated 18%)\n",
            "  adding: content/output_depth/467_depth.png (deflated 16%)\n",
            "  adding: content/output_depth/485_depth.png (deflated 22%)\n",
            "  adding: content/output_depth/487_depth.png (deflated 28%)\n",
            "  adding: content/output_depth/493_depth.png (deflated 17%)\n",
            "  adding: content/output_depth/468_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/478_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/497_depth.png (deflated 19%)\n",
            "  adding: content/output_depth/506_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/496_depth.png (deflated 16%)\n",
            "  adding: content/output_depth/475_depth.png (deflated 14%)\n",
            "  adding: content/output_depth/480_depth.png (deflated 16%)\n",
            "  adding: content/output_depth/503_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/489_depth.png (deflated 24%)\n",
            "  adding: content/output_depth/498_depth.png (deflated 19%)\n",
            "  adding: content/output_depth/479_depth.png (deflated 17%)\n",
            "  adding: content/output_depth/473_depth.png (deflated 16%)\n",
            "  adding: content/output_depth/488_depth.png (deflated 25%)\n",
            "  adding: content/output_depth/492_depth.png (deflated 17%)\n",
            "  adding: content/output_depth/500_depth.png (deflated 19%)\n",
            "  adding: content/output_depth/502_depth.png (deflated 20%)\n",
            "  adding: content/output_depth/474_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/477_depth.png (deflated 15%)\n",
            "  adding: content/output_depth/499_depth.png (deflated 18%)\n",
            "  adding: content/output_depth/515_depth.png (deflated 21%)\n",
            "  adding: content/output_depth/504_depth.png (deflated 19%)\n"
          ]
        }
      ],
      "source": [
        "# Zip the specified folder\n",
        "!zip -r /content/output_depth.zip /content/output_depth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7418905d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "7418905d",
        "outputId": "25c390c0-27c2-4ed3-ea44-72c4f7ab661f"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_0f3992bd-4543-403c-87ac-f59df524e8d6\", \"output_depth.zip\", 8787073)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the zipped file\n",
        "files.download('/content/output_depth.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final code DPT_Hybrid"
      ],
      "metadata": {
        "id": "EPzxmikH55qd"
      },
      "id": "EPzxmikH55qd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3wBJV9MW-Pax",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wBJV9MW-Pax",
        "outputId": "8d166b15-1222-4885-8a25-b0a9668e3035"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n",
            "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Processed 467.png → pre_depth/467.png\n",
            "✅ Processed 470.png → pre_depth/470.png\n",
            "✅ Processed 466.png → pre_depth/466.png\n",
            "✅ Processed 469.png → pre_depth/469.png\n",
            "✅ Processed 468.png → pre_depth/468.png\n",
            "✅ Processed 474.png → pre_depth/474.png\n",
            "✅ Processed 472.png → pre_depth/472.png\n",
            "✅ Processed 477.png → pre_depth/477.png\n",
            "✅ Processed 495.png → pre_depth/495.png\n",
            "✅ Processed 478.png → pre_depth/478.png\n",
            "✅ Processed 476.png → pre_depth/476.png\n",
            "✅ Processed 490.png → pre_depth/490.png\n",
            "✅ Processed 471.png → pre_depth/471.png\n",
            "✅ Processed 480.png → pre_depth/480.png\n",
            "✅ Processed 475.png → pre_depth/475.png\n",
            "✅ Processed 482.png → pre_depth/482.png\n",
            "✅ Processed 473.png → pre_depth/473.png\n",
            "✅ Processed 479.png → pre_depth/479.png\n",
            "✅ Processed 492.png → pre_depth/492.png\n",
            "✅ Processed 483.png → pre_depth/483.png\n",
            "✅ Processed 494.png → pre_depth/494.png\n",
            "✅ Processed 489.png → pre_depth/489.png\n",
            "✅ Processed 484.png → pre_depth/484.png\n",
            "✅ Processed 493.png → pre_depth/493.png\n",
            "✅ Processed 486.png → pre_depth/486.png\n",
            "✅ Processed 487.png → pre_depth/487.png\n",
            "✅ Processed 496.png → pre_depth/496.png\n",
            "✅ Processed 481.png → pre_depth/481.png\n",
            "✅ Processed 491.png → pre_depth/491.png\n",
            "✅ Processed 485.png → pre_depth/485.png\n",
            "✅ Processed 488.png → pre_depth/488.png\n",
            "✅ Processed 503.png → pre_depth/503.png\n",
            "✅ Processed 507.png → pre_depth/507.png\n",
            "✅ Processed 511.png → pre_depth/511.png\n",
            "✅ Processed 509.png → pre_depth/509.png\n",
            "✅ Processed 508.png → pre_depth/508.png\n",
            "✅ Processed 506.png → pre_depth/506.png\n",
            "✅ Processed 510.png → pre_depth/510.png\n",
            "✅ Processed 501.png → pre_depth/501.png\n",
            "✅ Processed 500.png → pre_depth/500.png\n",
            "✅ Processed 502.png → pre_depth/502.png\n",
            "✅ Processed 504.png → pre_depth/504.png\n",
            "✅ Processed 498.png → pre_depth/498.png\n",
            "✅ Processed 505.png → pre_depth/505.png\n",
            "✅ Processed 499.png → pre_depth/499.png\n",
            "✅ Processed 497.png → pre_depth/497.png\n",
            "✅ Processed 514.png → pre_depth/514.png\n",
            "✅ Processed 513.png → pre_depth/513.png\n",
            "✅ Processed 515.png → pre_depth/515.png\n",
            "✅ Processed 512.png → pre_depth/512.png\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torchvision.transforms import Compose, Normalize\n",
        "\n",
        "# 1. اختار الجهاز (GPU لو متاح)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. حمّل موديل MiDaS\n",
        "midas = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Hybrid\")\n",
        "midas.to(device)\n",
        "midas.eval()\n",
        "\n",
        "# 3. حمل الـ transforms الخاصة بالموديل\n",
        "midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n",
        "transform = midas_transforms.dpt_transform\n",
        "\n",
        "# 4. عرف فولدرات\n",
        "input_folder = \"/content/drive/MyDrive/data/images/left\"\n",
        "output_folder = \"pre_depth\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 5. لف على كل الصور في الفولدر\n",
        "for img_name in os.listdir(input_folder):\n",
        "    if img_name.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "        img_path = os.path.join(input_folder, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # preprocess\n",
        "        input_batch = transform(img).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            prediction = midas(input_batch)\n",
        "            prediction = torch.nn.functional.interpolate(\n",
        "                prediction.unsqueeze(1),\n",
        "                size=img.shape[:2],\n",
        "                mode=\"bicubic\",\n",
        "                align_corners=False,\n",
        "            ).squeeze()\n",
        "\n",
        "        # Convert to numpy\n",
        "        depth_map = prediction.cpu().numpy()  # real depth values\n",
        "\n",
        "        # Save depth as 32-bit single channel image\n",
        "        out_path = os.path.join(output_folder, f\"{os.path.splitext(img_name)[0]}.png\")\n",
        "        cv2.imwrite(out_path, depth_map.astype(np.float32))  # preserves real values\n",
        "\n",
        "        print(f\"✅ Processed {img_name} → {out_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# final code DepthPro-hf"
      ],
      "metadata": {
        "id": "yvIx560a5bhh"
      },
      "id": "yvIx560a5bhh"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from transformers import DepthProImageProcessorFast, DepthProForDepthEstimation\n",
        "\n",
        "# 1. الجهاز\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. حمّل الموديل والـ processor\n",
        "processor = DepthProImageProcessorFast.from_pretrained(\"apple/DepthPro-hf\")\n",
        "depthpro_model_hf = DepthProForDepthEstimation.from_pretrained(\"apple/DepthPro-hf\").to(device)\n",
        "depthpro_model_hf.eval()\n",
        "\n",
        "# 3. الفولدرات\n",
        "input_folder = \"/content/drive/MyDrive/data/images/left\"    # حطي هنا مسار فولدر الصور\n",
        "output_folder = \"/content/output_depth\"   # فولدر لحفظ النتائج\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# 4. المجال بتاع GT\n",
        "GT_MIN, GT_MAX = 2, 255\n",
        "\n",
        "# 5. لفة على كل الصور\n",
        "for file_name in os.listdir(input_folder):\n",
        "    if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
        "        img_path = os.path.join(input_folder, file_name)\n",
        "        output_path = os.path.join(output_folder, file_name)  # نفس الاسم جوه فولدر النتائج\n",
        "\n",
        "        # ---- Load + preprocess ----\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        inputs = processor(images=img, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # ---- استنتاج ----\n",
        "        with torch.no_grad():\n",
        "            outputs = depthpro_model_hf(**inputs)\n",
        "\n",
        "        post_processed = processor.post_process_depth_estimation(\n",
        "            outputs, target_sizes=[(img.height, img.width)]\n",
        "        )\n",
        "        depth_map_m = post_processed[0][\"predicted_depth\"].cpu().numpy()\n",
        "\n",
        "        # ---- Normalize [GT_MIN, GT_MAX] ----\n",
        "        d_min, d_max = depth_map_m.min(), depth_map_m.max()\n",
        "        depth_scaled = (depth_map_m - d_min) / (d_max - d_min)\n",
        "        depth_uint8 = (depth_scaled * (GT_MAX - GT_MIN) + GT_MIN).clip(GT_MIN, GT_MAX).astype(np.uint8)\n",
        "\n",
        "        # ---- Save ----\n",
        "        cv2.imwrite(output_path, depth_uint8)\n",
        "        print(f\"✅ Processed {img_path} → {output_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtuOtrdaws5L",
        "outputId": "49485eab-cc46-47cd-844b-a51a813e1ff3"
      },
      "id": "qtuOtrdaws5L",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Processed /content/drive/MyDrive/data/images/left/466.png → /content/output_depth/466.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/478.png → /content/output_depth/478.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/467.png → /content/output_depth/467.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/480.png → /content/output_depth/480.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/472.png → /content/output_depth/472.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/476.png → /content/output_depth/476.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/470.png → /content/output_depth/470.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/473.png → /content/output_depth/473.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/481.png → /content/output_depth/481.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/477.png → /content/output_depth/477.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/474.png → /content/output_depth/474.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/471.png → /content/output_depth/471.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/482.png → /content/output_depth/482.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/479.png → /content/output_depth/479.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/475.png → /content/output_depth/475.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/468.png → /content/output_depth/468.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/469.png → /content/output_depth/469.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/486.png → /content/output_depth/486.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/498.png → /content/output_depth/498.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/495.png → /content/output_depth/495.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/484.png → /content/output_depth/484.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/496.png → /content/output_depth/496.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/502.png → /content/output_depth/502.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/491.png → /content/output_depth/491.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/497.png → /content/output_depth/497.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/488.png → /content/output_depth/488.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/494.png → /content/output_depth/494.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/487.png → /content/output_depth/487.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/499.png → /content/output_depth/499.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/490.png → /content/output_depth/490.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/493.png → /content/output_depth/493.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/483.png → /content/output_depth/483.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/500.png → /content/output_depth/500.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/485.png → /content/output_depth/485.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/492.png → /content/output_depth/492.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/501.png → /content/output_depth/501.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/489.png → /content/output_depth/489.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/512.png → /content/output_depth/512.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/504.png → /content/output_depth/504.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/511.png → /content/output_depth/511.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/503.png → /content/output_depth/503.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/508.png → /content/output_depth/508.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/506.png → /content/output_depth/506.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/513.png → /content/output_depth/513.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/505.png → /content/output_depth/505.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/514.png → /content/output_depth/514.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/507.png → /content/output_depth/507.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/510.png → /content/output_depth/510.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/509.png → /content/output_depth/509.png\n",
            "✅ Processed /content/drive/MyDrive/data/images/left/515.png → /content/output_depth/515.png\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}